{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing the machine learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "print(\"Doing the machine learning...\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LAYERS = [8,16,16,1]\n",
    "\n",
    "dataset = numpy.loadtxt(\"MakeathonAccept.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:LAYERS[0]]\n",
    "Y = dataset[:,LAYERS[0]:LAYERS[0] + 1]\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(LAYERS[0], input_dim=LAYERS[0], activation='relu'))\n",
    "model.add(Dense(LAYERS[1], activation='relu'))\n",
    "model.add(Dense(LAYERS[2], activation='relu'))\n",
    "model.add(Dense(LAYERS[3], activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 516 samples, validate on 172 samples\n",
      "Epoch 1/50\n",
      "516/516 [==============================] - 0s - loss: 0.3464 - acc: 0.8643 - val_loss: 0.4642 - val_acc: 0.8372\n",
      "Epoch 2/50\n",
      "516/516 [==============================] - 0s - loss: 0.3442 - acc: 0.8702 - val_loss: 0.4534 - val_acc: 0.8372\n",
      "Epoch 3/50\n",
      "516/516 [==============================] - 0s - loss: 0.3408 - acc: 0.8702 - val_loss: 0.4594 - val_acc: 0.8372\n",
      "Epoch 4/50\n",
      "516/516 [==============================] - 0s - loss: 0.3410 - acc: 0.8702 - val_loss: 0.4575 - val_acc: 0.8372\n",
      "Epoch 5/50\n",
      "516/516 [==============================] - 0s - loss: 0.3446 - acc: 0.8624 - val_loss: 0.4712 - val_acc: 0.8372\n",
      "Epoch 6/50\n",
      "516/516 [==============================] - 0s - loss: 0.3434 - acc: 0.8663 - val_loss: 0.4618 - val_acc: 0.8372\n",
      "Epoch 7/50\n",
      "516/516 [==============================] - 0s - loss: 0.3408 - acc: 0.8663 - val_loss: 0.4648 - val_acc: 0.8372\n",
      "Epoch 8/50\n",
      "516/516 [==============================] - 0s - loss: 0.3421 - acc: 0.8663 - val_loss: 0.4597 - val_acc: 0.8372\n",
      "Epoch 9/50\n",
      "516/516 [==============================] - 0s - loss: 0.3404 - acc: 0.8663 - val_loss: 0.4626 - val_acc: 0.8372\n",
      "Epoch 10/50\n",
      "516/516 [==============================] - 0s - loss: 0.3427 - acc: 0.8663 - val_loss: 0.4656 - val_acc: 0.8372\n",
      "Epoch 11/50\n",
      "516/516 [==============================] - 0s - loss: 0.3420 - acc: 0.8624 - val_loss: 0.4640 - val_acc: 0.8372\n",
      "Epoch 12/50\n",
      "516/516 [==============================] - 0s - loss: 0.3431 - acc: 0.8663 - val_loss: 0.4572 - val_acc: 0.8372\n",
      "Epoch 13/50\n",
      "516/516 [==============================] - 0s - loss: 0.3441 - acc: 0.8663 - val_loss: 0.4559 - val_acc: 0.8372\n",
      "Epoch 14/50\n",
      "516/516 [==============================] - 0s - loss: 0.3417 - acc: 0.8663 - val_loss: 0.4676 - val_acc: 0.8372\n",
      "Epoch 15/50\n",
      "516/516 [==============================] - 0s - loss: 0.3414 - acc: 0.8682 - val_loss: 0.4545 - val_acc: 0.8430\n",
      "Epoch 16/50\n",
      "516/516 [==============================] - 0s - loss: 0.3449 - acc: 0.8663 - val_loss: 0.4589 - val_acc: 0.8372\n",
      "Epoch 17/50\n",
      "516/516 [==============================] - 0s - loss: 0.3448 - acc: 0.8682 - val_loss: 0.4591 - val_acc: 0.8372\n",
      "Epoch 18/50\n",
      "516/516 [==============================] - 0s - loss: 0.3395 - acc: 0.8663 - val_loss: 0.4556 - val_acc: 0.8314\n",
      "Epoch 19/50\n",
      "516/516 [==============================] - 0s - loss: 0.3453 - acc: 0.8682 - val_loss: 0.4616 - val_acc: 0.8372\n",
      "Epoch 20/50\n",
      "516/516 [==============================] - 0s - loss: 0.3386 - acc: 0.8682 - val_loss: 0.4498 - val_acc: 0.8372\n",
      "Epoch 21/50\n",
      "516/516 [==============================] - 0s - loss: 0.3437 - acc: 0.8643 - val_loss: 0.4575 - val_acc: 0.8372\n",
      "Epoch 22/50\n",
      "516/516 [==============================] - 0s - loss: 0.3374 - acc: 0.8682 - val_loss: 0.4586 - val_acc: 0.8372\n",
      "Epoch 23/50\n",
      "516/516 [==============================] - 0s - loss: 0.3375 - acc: 0.8682 - val_loss: 0.4592 - val_acc: 0.8372\n",
      "Epoch 24/50\n",
      "516/516 [==============================] - 0s - loss: 0.3367 - acc: 0.8682 - val_loss: 0.4603 - val_acc: 0.8372\n",
      "Epoch 25/50\n",
      "516/516 [==============================] - 0s - loss: 0.3418 - acc: 0.8663 - val_loss: 0.4750 - val_acc: 0.8372\n",
      "Epoch 26/50\n",
      "516/516 [==============================] - 0s - loss: 0.3384 - acc: 0.8682 - val_loss: 0.4699 - val_acc: 0.8372\n",
      "Epoch 27/50\n",
      "516/516 [==============================] - 0s - loss: 0.3420 - acc: 0.8721 - val_loss: 0.4588 - val_acc: 0.8372\n",
      "Epoch 28/50\n",
      "516/516 [==============================] - 0s - loss: 0.3366 - acc: 0.8663 - val_loss: 0.4575 - val_acc: 0.8372\n",
      "Epoch 29/50\n",
      "516/516 [==============================] - 0s - loss: 0.3381 - acc: 0.8663 - val_loss: 0.4537 - val_acc: 0.8372\n",
      "Epoch 30/50\n",
      "516/516 [==============================] - 0s - loss: 0.3362 - acc: 0.8702 - val_loss: 0.4588 - val_acc: 0.8372\n",
      "Epoch 31/50\n",
      "516/516 [==============================] - 0s - loss: 0.3349 - acc: 0.8721 - val_loss: 0.4538 - val_acc: 0.8372\n",
      "Epoch 32/50\n",
      "516/516 [==============================] - 0s - loss: 0.3365 - acc: 0.8702 - val_loss: 0.4549 - val_acc: 0.8372\n",
      "Epoch 33/50\n",
      "516/516 [==============================] - 0s - loss: 0.3360 - acc: 0.8682 - val_loss: 0.4654 - val_acc: 0.8314\n",
      "Epoch 34/50\n",
      "516/516 [==============================] - 0s - loss: 0.3380 - acc: 0.8663 - val_loss: 0.4619 - val_acc: 0.8372\n",
      "Epoch 35/50\n",
      "516/516 [==============================] - 0s - loss: 0.3404 - acc: 0.8663 - val_loss: 0.4478 - val_acc: 0.8372\n",
      "Epoch 36/50\n",
      "516/516 [==============================] - 0s - loss: 0.3348 - acc: 0.8682 - val_loss: 0.4591 - val_acc: 0.8314\n",
      "Epoch 37/50\n",
      "516/516 [==============================] - 0s - loss: 0.3337 - acc: 0.8682 - val_loss: 0.4679 - val_acc: 0.8314\n",
      "Epoch 38/50\n",
      "516/516 [==============================] - 0s - loss: 0.3397 - acc: 0.8721 - val_loss: 0.4597 - val_acc: 0.8372\n",
      "Epoch 39/50\n",
      "516/516 [==============================] - 0s - loss: 0.3370 - acc: 0.8643 - val_loss: 0.4636 - val_acc: 0.8314\n",
      "Epoch 40/50\n",
      "516/516 [==============================] - 0s - loss: 0.3339 - acc: 0.8702 - val_loss: 0.4486 - val_acc: 0.8372\n",
      "Epoch 41/50\n",
      "516/516 [==============================] - 0s - loss: 0.3343 - acc: 0.8663 - val_loss: 0.4569 - val_acc: 0.8372\n",
      "Epoch 42/50\n",
      "516/516 [==============================] - 0s - loss: 0.3326 - acc: 0.8721 - val_loss: 0.4632 - val_acc: 0.8314\n",
      "Epoch 43/50\n",
      "516/516 [==============================] - 0s - loss: 0.3325 - acc: 0.8702 - val_loss: 0.4650 - val_acc: 0.8372\n",
      "Epoch 44/50\n",
      "516/516 [==============================] - 0s - loss: 0.3345 - acc: 0.8643 - val_loss: 0.4612 - val_acc: 0.8256\n",
      "Epoch 45/50\n",
      "516/516 [==============================] - 0s - loss: 0.3338 - acc: 0.8702 - val_loss: 0.4601 - val_acc: 0.8372\n",
      "Epoch 46/50\n",
      "516/516 [==============================] - 0s - loss: 0.3316 - acc: 0.8702 - val_loss: 0.4629 - val_acc: 0.8372\n",
      "Epoch 47/50\n",
      "516/516 [==============================] - 0s - loss: 0.3381 - acc: 0.8624 - val_loss: 0.4544 - val_acc: 0.8372\n",
      "Epoch 48/50\n",
      "516/516 [==============================] - 0s - loss: 0.3359 - acc: 0.8682 - val_loss: 0.4706 - val_acc: 0.8372\n",
      "Epoch 49/50\n",
      "516/516 [==============================] - 0s - loss: 0.3324 - acc: 0.8702 - val_loss: 0.4569 - val_acc: 0.8314\n",
      "Epoch 50/50\n",
      "516/516 [==============================] - 0s - loss: 0.3308 - acc: 0.8682 - val_loss: 0.4589 - val_acc: 0.8314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1190dbf98>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=50, batch_size=10, shuffle=True, validation_split=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your name: anand\n",
      "Hello anand\n",
      "When did or will you graduate? 4\n",
      "What is your level of education? (0 = undergrad, 1 = master, 2 = doctoral, 3 = no school) 1\n",
      "Are you a Business Designer(0), Designer(1), Technologist(2), or something else(3)?2\n",
      "What is your craft score? (inputted by HR)3\n",
      "What is your Resume Score? (NLP)3\n",
      "What is your Cover Letter Score? (NLP)3\n",
      "Your Prediction:  88.3265554905\n"
     ]
    }
   ],
   "source": [
    "# USER APPLY TEST\n",
    "\n",
    "# scores = model.evaluate(testX, testY)\n",
    "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# Predict your chance of getting into CoLab!\n",
    "name = input('Enter your name: ')\n",
    "print('Hello', name)\n",
    "gradYear = int(input('When did or will you graduate? (enter 0 if before 2010)'))\n",
    "gradYear = gradYear%10\n",
    "levelEdu = int(input('What is your level of education? (0 = undergrad, 1 = master, 2 = doctoral, 3 = no school) '))\n",
    "skill = int(input('Are you a Business Designer(0), Designer(1), Technologist(2), or something else(3)?'))\n",
    "craft = int(input('What is your craft score? (inputted by HR)'))\n",
    "r1 = int(input('What is your Resume Score? (NLP)'))\n",
    "r2 = int(input('What is your Cover Letter Score? (NLP)'))\n",
    "totalR = r1+r2\n",
    "totalAll = totalR + craft\n",
    "userData = numpy.array([[gradYear, levelEdu, skill, craft, r1, r2, totalR, totalAll]])\n",
    "\n",
    "# calculate predictions\n",
    "# testY = testdataset[:,8]\n",
    "yourPrediction = model.predict(userData, batch_size=1, verbose=0)\n",
    "print(\"Your Prediction: \", yourPrediction[0][0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other Predictions:  [[ 0.1153771 ]\n",
      " [ 0.12608032]\n",
      " [ 0.10539994]\n",
      " [ 0.10866401]\n",
      " [ 0.88783914]\n",
      " [ 0.05682819]\n",
      " [ 0.80805755]\n",
      " [ 0.07731063]]\n"
     ]
    }
   ],
   "source": [
    "# TEST DATASET\n",
    "testdataset = numpy.loadtxt(\"MakeathonFinalTest.csv\", delimiter=\",\")\n",
    "testX = testdataset[:,0:LAYERS[0]]\n",
    "testY = testdataset[:,LAYERS[0]]\n",
    "\n",
    "predictions = model.predict(testX, batch_size=1, verbose=0)\n",
    "print(\"Other Predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c9efe254874979865788771b74b919"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INTERACTIVE TEST\n",
    "\n",
    "gradScore = widgets.FloatSlider(min=2011, max=2020, step=1, value=0)\n",
    "educationLevelScore = widgets.FloatSlider(min=0, max=3, step=1, value=0)\n",
    "skillScore = widgets.FloatSlider(min=0, max=3, step=1, value=0)\n",
    "craftScore = widgets.FloatSlider(min=0, max=3, step=.25, value=0)\n",
    "r1Score = widgets.FloatSlider(min=0, max=3, step=.5, value=0)\n",
    "r2Score = widgets.FloatSlider(min=0, max=3, step=.5, value=0)\n",
    "\n",
    "\n",
    "@interact(grad = gradScore, eduLevel = educationLevelScore, skill = skillScore, craft = craftScore,  \n",
    "          r1 = r1Score, r2 = r2Score)\n",
    "\n",
    "def test(grad, eduLevel, skill, craft, r1, r2):\n",
    "    totalRScore = r1+r2\n",
    "    totalAllScore = totalRScore + craft\n",
    "    grad = grad%10\n",
    "    userData = numpy.array([[grad, eduLevel, skill, craft, r1, r2, totalRScore, totalAllScore]])\n",
    "    yourPrediction = model.predict(userData, batch_size=1, verbose=0)\n",
    "    print('eduLevel: 0 = undergrad, 1 = masters, 2 = doctoral, 3 = none')\n",
    "    print('skill: 0 = BD, 1 = D, 2 = T, 3 = W\\n')\n",
    "    print(\"Your Prediction: \", yourPrediction[0][0]*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
